{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQvCYX2J8+BY2fKydAeLve"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalación e importación de bibliotecas"
      ],
      "metadata": {
        "id": "qbEbC3Cp1tJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/angelfergar/ChurnRetention-SP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUtqJcH41w2-",
        "outputId": "eabc0ebb-cd8c-4d3a-cec1-7a1d0cb83e85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChurnRetention-SP'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 48 (delta 15), reused 20 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 2.55 MiB | 9.18 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Ju9kFLZ1mdH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_score, recall_score, f1_score, average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/ChurnRetention-SP/data/preprocessed_customerChurn.csv'\n",
        "df = pd.read_csv(dataset_path)"
      ],
      "metadata": {
        "id": "xtcLibBY14q3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Equilibrado de datos"
      ],
      "metadata": {
        "id": "ksnVUMkF1_-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos los dataset que usaremos para el entrenamiento de los modelos"
      ],
      "metadata": {
        "id": "D9saPSoD2DPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_X = df.drop('Churn Label', axis=1)\n",
        "df_y = df['Churn Label']"
      ],
      "metadata": {
        "id": "KJEmNPZX2sMt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "0ANMlg3g25CW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentamos de forma sintética la clase minoritaria un 65% y reduce la clase mayoritaria en un 25% (Se llega a estas cifras a base de prueba y error). De esta forma, pasamos de tener una proporción de 3:1 a una de 1.25 sin introducir un exceso de ruido que pueda provocar overfitting en el modelo ni perder una gran cantidad de datos."
      ],
      "metadata": {
        "id": "4V0nlICy28lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(sampling_strategy=0.6)\n",
        "under = RandomUnderSampler(sampling_strategy=0.8)\n",
        "\n",
        "# Creamos un pipeline para aplicar ambas técnicas a la vez\n",
        "pipeline = Pipeline([('smote', smote), ('under', under)])\n",
        "\n",
        "# Obtenemos dos nuevos datasets con los datos equilibrados\n",
        "X_train_smote, y_train_smote = pipeline.fit_resample(X_train, y_train)\n",
        "\n",
        "print('Distribución de clases antes de Balanceo:', y_train.value_counts())\n",
        "print('Distribución de clases después de Balanceo:', pd.Series(y_train_smote).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mAKys6529bH",
        "outputId": "b0946e36-9404-485d-f57d-56bd1624fcd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de clases antes de Balanceo: Churn Label\n",
            "0    3615\n",
            "1    1315\n",
            "Name: count, dtype: int64\n",
            "Distribución de clases después de Balanceo: Churn Label\n",
            "0    2711\n",
            "1    2169\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este ajuste no supone una reducción excesiva ya que se han eliminado 904 muestras de la clase mayoritaria. De la misma forma, el haber añadido, de forma sintética, 854 muestras a la clase minoritaria no debería crear mucho ruido a la hora de desarrollar los modelos, por lo que no tendría que haber problemas de overfitting.\n",
        "\n",
        "Este equilibrado se utilizará como punto de partida para optimizar los\n",
        "diferentes modelos, pero se usarán una serie de valores adicionales a los elegidos cuando apliquemos las técnicas de validación cruzada y grid search sobre el modelo que mejores métricas haya obtenido.\n",
        "\n"
      ],
      "metadata": {
        "id": "TaQ5GyyC3k5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Entrenamiento de los modelos"
      ],
      "metadata": {
        "id": "zfvCTX8S3bcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado vamos a trabajar con cinco modelos de machine learning: **Linear Regression, Decision Tree, Random Forest, XGBoost y LightGBM.** El objetivo es entrenar los modelos y analizar las métricas que son más relevantes en el caso tratado.\n",
        "\n",
        "Al contar con un cierto desbalance en el dataset, métricas como Precision y Recall pueden no ser suficientes para evaluar el rendimiento de los modelos. Por una parte, la precisión podría verse afectada por el incremento de falsos positivos, dado que SMOTE ha generado casos sintéticos que podrían aumentar las predicciones de los clientes que se han dado de baja. Por otra parte, el Recall podría aumentar por el mayor énfasis dado a la clase minoritaria, pero esto no significa que se pueda garantizar que las predicciones sean consistentes o útiles en el contexto trabajado.\n",
        "\n",
        "Debido a estas razones, **usaremos F1-Score como métrica principal** para determinar la eficacia de los modelos. Esto se debe a que combina Precision y Recall, penalizando modelos que tengan un desequilibrio entre ambas. Esto es particularmente importante tras haber aplicado las técnicas de equilibrado de datos, ya que el F1-Score permite verificar si el modelo realmente ha aprendido a identificar de manera efectiva los casos de clientes que se han dado de baja.\n",
        "\n",
        "También **usaremos otras métricas como la ROC Curve y la Precision-Recall Curve**. Es cierto que la ROC Curve ya que el dataset tratado cuenta con un cierto rango de desbalanceo, y esta métrica tiende a obtener una mayoría de verdaderos negativos, lo que puede hacer que esta métrica se vea un poco inflada. Por ello, también analizaremos la Precisión-Recall Curve, ya que esta es mucho más óptima en contextos donde existan desequilibrios entre las clases, ya que refleja cual es el rendimiento de la clase minoritaria.\n",
        "\n"
      ],
      "metadata": {
        "id": "aHXC4O1w3g0a"
      }
    }
  ]
}